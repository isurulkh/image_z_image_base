{
  "input": {
    "workflow": {
      "9": {
        "inputs": {
          "filename_prefix": "z-image",
          "images": [
            "65",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "SaveImage"
        }
      },
      "62": {
        "inputs": {
          "filename": "qwen_3_4b.safetensors"
        },
        "class_type": "CLIPLoader",
        "_meta": {
          "title": "CLIPLoader"
        }
      },
      "63": {
        "inputs": {
          "filename": "ae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "VAELoader"
        }
      },
      "65": {
        "inputs": {
          "samples": [
            "69",
            0
          ],
          "vae": [
            "63",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAEDecode"
        }
      },
      "66": {
        "inputs": {
          "filename": "z_image_bf16.safetensors"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "UNETLoader"
        }
      },
      "67": {
        "inputs": {
          "text": [
            "78",
            0
          ],
          "clip": [
            "62",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Positive Prompt)"
        }
      },
      "68": {
        "inputs": {
          "width": 1024,
          "height": 1024,
          "batch_size": 1
        },
        "class_type": "EmptySD3LatentImage",
        "_meta": {
          "title": "EmptySD3LatentImage"
        }
      },
      "69": {
        "inputs": {
          "seed": 1005236999609127,
          "steps": 25,
          "cfg": 4,
          "sampler_name": "res_multistep",
          "scheduler": "simple",
          "denoise": 1,
          "model": [
            "70",
            0
          ],
          "positive": [
            "67",
            0
          ],
          "negative": [
            "71",
            0
          ],
          "latent_image": [
            "68",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "70": {
        "inputs": {
          "value": 3,
          "model": [
            "66",
            0
          ]
        },
        "class_type": "ModelSamplingAuraFlow",
        "_meta": {
          "title": "ModelSamplingAuraFlow"
        }
      },
      "71": {
        "inputs": {
          "text": "",
          "clip": [
            "62",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Negative Prompt)"
        }
      },
      "77": {
        "inputs": {
          "filename": "an1ta, close-up shot capturing a blonde woman with closed eyes, lips parted around a erect penis inserted deep into her mouth; she has smooth fair skin, subtle blush, defined eyebrows, and damp strands of light blonde hair falling near her shoulder; the male’s lower torso and pubic area are partially visible from behind, showing dark underarm hair and a prominent testicle; shallow depth-of-field blurs the background which appears to be a windowed room with bright daylight casting soft shadows across their bodies; intimate, candid moment captured with raw realism—naturalistic textures, moist surfaces, slight droplets clinging to chin and lip edges—and tight framing emphasizing the action while preserving anatomical detail without stylization or embellishment.",
          "anything": [
            "78",
            0
          ]
        },
        "class_type": "easy showAnything",
        "_meta": {
          "title": "easy showAnything"
        }
      },
      "78": {
        "inputs": {
          "text": "Qwen3-VL-4B-Instruct",
          "image": [
            "81",
            0
          ],
          "custom_prompt": [
            "80",
            0
          ]
        },
        "class_type": "AILab_QwenVL",
        "_meta": {
          "title": "AILab_QwenVL"
        }
      },
      "80": {
        "inputs": {
          "filename": "You are a highly observant visual analysis expert and professional AI prompt builder, specialized in converting images into high-quality, production-ready prompts for advanced text-to-image models such as LTX, Flux, SDXL, and ComfyUI workflows.\n\nYou are generating prompts specifically intended to be used with the an1ta LoRA.\n\nYour task is to analyze a single input image and produce one polished English prompt that allows an AI model using the an1ta LoRA to faithfully recreate the image with maximum realism and visual precision.\n\nMandatory an1ta Integration\n\nThe generated prompt must explicitly include the token an1ta.\n\nIntegrate an1ta naturally at the beginning of the prompt or directly before the main subject description.\n\nDo not explain what an1ta is. Just include it as a style and identity anchor.\n\nStep 1: Subject Determination and Description\n\nFirst, determine the subject type of the image:\n\nPerson\n\nArchitecture or interior space\n\nLandscape\n\nStill life or product\n\nThen proceed accordingly:\n\nIf the image contains a person, prioritize face details first, including facial structure, skin texture, expression, eyes, hair, makeup if visible, and fine micro-details. Then describe the upper body, clothing, visible hands, posture, and body language. Never invent identity, age, ethnicity, or features that are not clearly visible.\n\nIf the image shows architecture or space, describe architectural style, structure, materials, geometry, and perspective. Do not introduce people if none are visible.\n\nIf the image is a still life or product, focus on materials, surface texture, reflections, color palette, and physical arrangement.\n\nIf the image contains no people, do not use words such as man, woman, person, or pedestrian.\n\nStep 2: Environment and Lighting\n\nDescribe the environment only if it is visible. Include background depth, spatial separation, and atmosphere.\n\nClearly describe lighting characteristics, including source type, direction, softness, contrast, shadow behavior, and overall mood.\n\nStep 3: Composition and Perspective\n\nDescribe the camera language precisely, including framing, lens type if inferable, depth of field, focus behavior, angle, and composition style.\n\nOutput Requirements\n\nOutput one single coherent paragraph of natural English text.\n\nNo bullet points.\n\nNo explanations, summaries, or meta commentary.\n\nNever invent elements not visible in the image.\n\nDo not mention watermarks, UI elements, or irrelevant symbols.\n\nMaintain a cinematic, realistic, handcrafted tone.\n\nLimit the output to 1000 characters maximum.\n\nGoal\n\nGenerate the highest-quality an1ta-compatible descriptive prompt possible, ensuring the text-to-image model can accurately reproduce the subject, style, and atmosphere of the original image."
        },
        "class_type": "JjkText",
        "_meta": {
          "title": "META-PROMPT."
        }
      },
      "81": {
        "inputs": {
          "image": "ComfyUI_03971_.png"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "LoadImage"
        }
      },
      "83": {
        "inputs": {
          "filename": "seedvr2_ema_7b_fp16.safetensors"
        },
        "class_type": "SeedVR2LoadDiTModel",
        "_meta": {
          "title": "SeedVR2LoadDiTModel"
        }
      },
      "84": {
        "inputs": {
          "filename": "ema_vae_fp16.safetensors"
        },
        "class_type": "SeedVR2LoadVAEModel",
        "_meta": {
          "title": "SeedVR2LoadVAEModel"
        }
      },
      "85": {
        "inputs": {
          "value": 1274110942,
          "image": [
            "65",
            0
          ],
          "dit": [
            "83",
            0
          ],
          "vae": [
            "84",
            0
          ]
        },
        "class_type": "SeedVR2VideoUpscaler",
        "_meta": {
          "title": "SeedVR2VideoUpscaler"
        }
      },
      "86": {
        "inputs": {
          "value": true,
          "anything": [
            "85",
            0
          ]
        },
        "class_type": "LayerUtility: PurgeVRAM",
        "_meta": {
          "title": "LayerUtility: PurgeVRAM"
        }
      },
      "87": {
        "inputs": {
          "filename_prefix": "RedZimage2/demo2",
          "images": [
            "85",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "SaveImage"
        }
      },
      "88": {
        "inputs": {
          "images": [
            "85",
            0
          ]
        },
        "class_type": "PreviewImage",
        "_meta": {
          "title": "PreviewImage"
        }
      }
    }
  }
}